{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mbti_prediction_with_Bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhQedJ4O8A2R57Dh7Qf5Fw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a1529816ba2040aebb0f1612896569ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f2ae62ffc3a24e8ba06b29c6b769ca51",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_82324519eca040fd8072960ea38ba1ef",
              "IPY_MODEL_d4bb11593988482db4fd1df0cf127968"
            ]
          }
        },
        "f2ae62ffc3a24e8ba06b29c6b769ca51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82324519eca040fd8072960ea38ba1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe6e6dbec63f401598b9d989113972e0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_237d73a2663248e49c561a5e6d91c49c"
          }
        },
        "d4bb11593988482db4fd1df0cf127968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3203a0a065c843f1b62a91e3f1491484",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:26&lt;00:00, 37.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c94087184de430684f656fc3e231335"
          }
        },
        "fe6e6dbec63f401598b9d989113972e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "237d73a2663248e49c561a5e6d91c49c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3203a0a065c843f1b62a91e3f1491484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c94087184de430684f656fc3e231335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "339cab601f554c87b14bb71619a06037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6d7e9282f8b7474b971b40dfb4380301",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_73d5cb90a8354621966ac1bd11c0f65a",
              "IPY_MODEL_9de5fc3aee354c45940d8b071f3ee51d"
            ]
          }
        },
        "6d7e9282f8b7474b971b40dfb4380301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73d5cb90a8354621966ac1bd11c0f65a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_63290d34092f481b98f8e2e7a777f4d4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7fa5c76a06f0402bb60492abf0bc8ffd"
          }
        },
        "9de5fc3aee354c45940d8b071f3ee51d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_da632738b3914d04aee960b838dd8a2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:11&lt;00:00, 56.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61070751b4c24df896a6b69099633ef1"
          }
        },
        "63290d34092f481b98f8e2e7a777f4d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7fa5c76a06f0402bb60492abf0bc8ffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da632738b3914d04aee960b838dd8a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61070751b4c24df896a6b69099633ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8fe4251c906408896814605bfe3b6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b2d371163655495d9e45732ad4fab962",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3fd4db6f2a374a119acabdd60b963b7f",
              "IPY_MODEL_6673b0766b5c4f26b714a14bfdf49e77"
            ]
          }
        },
        "b2d371163655495d9e45732ad4fab962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fd4db6f2a374a119acabdd60b963b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1209b336c2d348f8a15c5cc6265cbf57",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05bd8cc22b9444c3a11361621a574a74"
          }
        },
        "6673b0766b5c4f26b714a14bfdf49e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_32dc52c3f96b45d1bf01ae9ae9e1778a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 714M/714M [00:10&lt;00:00, 65.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b1c90489a394488ea95552fc530e534f"
          }
        },
        "1209b336c2d348f8a15c5cc6265cbf57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05bd8cc22b9444c3a11361621a574a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32dc52c3f96b45d1bf01ae9ae9e1778a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b1c90489a394488ea95552fc530e534f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skdldbwls/predict_mbti_korean/blob/master/mbti_prediction_with_Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt2szrGnLyUJ"
      },
      "source": [
        "# **준비 사항**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ib13sgXLkwt",
        "outputId": "f56c0217-0887-4d6a-b007-ef3a24412a6a"
      },
      "source": [
        "# Hugging Face의 트랜스포머 모델을 설치\r\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 12.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=08c6d7f8364a286d0b172e963850b295bd47e7451076e77acda743948e9bf2e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abK9HgnRLvsc"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import torch\r\n",
        "\r\n",
        "from transformers import BertTokenizer\r\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\r\n",
        "from transformers import get_linear_schedule_with_warmup\r\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import time\r\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "8DRYoR-oL5T_",
        "outputId": "23a2cbcb-0f25-4a20-a77a-44c7f9f1dfc5"
      },
      "source": [
        "from google.colab import files\r\n",
        "myfile = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-acf92986-0570-4887-9844-3df2e1138639\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-acf92986-0570-4887-9844-3df2e1138639\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving data_winter_final.csv to data_winter_final.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "TgbOgUYyL_9u",
        "outputId": "49bc5b68-aab6-4fd2-baeb-3b8c7077a722"
      },
      "source": [
        "data = pd.read_csv(\"data_winter_final.csv\")\r\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ESTP</td>\n",
              "      <td>1. 최근 카페의 질의응답 게시판에 지속적으로 등업을 요구하는 글이 올라오고 있습니...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>INFP</td>\n",
              "      <td>제게 큰 현타를 주었던 글이에요.제 자신이 마음에 안 들고,늘 부족한 것 같고,절대...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ISFJ</td>\n",
              "      <td>유고슬라비아는 남슬라브 국가들(세르비아, 슬로베니아, 크로아티아, 보스니아, 북마케...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ISTP</td>\n",
              "      <td>10대 여자고 키도 크고 나이에 비해 성숙한 이미지를 가지고 있어요. 잇팁답게 차갑...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ISFP</td>\n",
              "      <td>제가 요즘 끌리는 남자가있는데 esfp인거같아요esfj인줄 알았는데 상황에따라 행동...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0  ESTP  1. 최근 카페의 질의응답 게시판에 지속적으로 등업을 요구하는 글이 올라오고 있습니...\n",
              "1  INFP  제게 큰 현타를 주었던 글이에요.제 자신이 마음에 안 들고,늘 부족한 것 같고,절대...\n",
              "2  ISFJ  유고슬라비아는 남슬라브 국가들(세르비아, 슬로베니아, 크로아티아, 보스니아, 북마케...\n",
              "3  ISTP  10대 여자고 키도 크고 나이에 비해 성숙한 이미지를 가지고 있어요. 잇팁답게 차갑...\n",
              "4  ISFP  제가 요즘 끌리는 남자가있는데 esfp인거같아요esfj인줄 알았는데 상황에따라 행동..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOVlD3r5aJCx"
      },
      "source": [
        "## mbti라벨링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OA6Zt7UVnyh",
        "outputId": "38e5b5b9-1fad-4fc0-ad8a-d3843eecd055"
      },
      "source": [
        "# Split mbti personality into 4 letters and binarize\r\n",
        "titles = [\"Extraversion (E) - Introversion (I)\",\r\n",
        "          \"Sensation (S) - INtuition (N)\",\r\n",
        "          \"Thinking (T) - Feeling (F)\",\r\n",
        "          \"Judgement (J) - Perception (P)\"\r\n",
        "         ] \r\n",
        "b_Pers = {'I':0, 'E':1, 'N':0, 'S':1, 'F':0, 'T':1, 'J':0, 'P':1}\r\n",
        "b_Pers_list = [{0:'I', 1:'E'}, {0:'N', 1:'S'}, {0:'F', 1:'T'}, {0:'J', 1:'P'}]\r\n",
        "\r\n",
        "\r\n",
        "#transform mbti to binary vector\r\n",
        "def translate_personality(personality):\r\n",
        "    return [b_Pers[l] for l in personality]\r\n",
        "\r\n",
        "#transform binary vector to mbti personality\r\n",
        "def translate_back(personality):\r\n",
        "    s = \"\"\r\n",
        "    for i, l in enumerate(personality):\r\n",
        "        s += b_Pers_list[i][l]\r\n",
        "    return s\r\n",
        "\r\n",
        "list_personality_bin = np.array([translate_personality(p) for p in data.type])\r\n",
        "print(\"Binarize MBTI list: \\n%s\" % list_personality_bin)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Binarize MBTI list: \n",
            "[[1 1 1 1]\n",
            " [0 0 0 1]\n",
            " [0 1 0 0]\n",
            " ...\n",
            " [0 0 0 0]\n",
            " [0 1 1 0]\n",
            " [0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysctkU8AWN7z"
      },
      "source": [
        "\r\n",
        "data['I-E'] = list_personality_bin[:,0]\r\n",
        "data['N-S'] = list_personality_bin[:,1]\r\n",
        "data['F-T'] = list_personality_bin[:,2]\r\n",
        "data['J-P'] = list_personality_bin[:,3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGP7FsjsXb9L"
      },
      "source": [
        "\r\n",
        "## train, test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JWUz50TXbBB",
        "outputId": "c6749296-ecfa-4197-f499-d9ed03562043"
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\r\n",
        "\r\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\r\n",
        "for train_index, test_index in split.split(data, data[['type']]):\r\n",
        "    strat_train_set = data.loc[train_index]\r\n",
        "    strat_test_set = data.loc[test_index]\r\n",
        "\r\n",
        "strat_train_set = strat_train_set.reset_index(drop=True)\r\n",
        "strat_test_set = strat_test_set.reset_index(drop=True)\r\n",
        "\r\n",
        "X_train = strat_train_set.posts\r\n",
        "X_test = strat_test_set.posts\r\n",
        "\r\n",
        "print(X_train.shape)\r\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24910,)\n",
            "(6228,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KK_KXaUXlfP",
        "outputId": "c8ea4dfe-0622-41e7-9fa1-f23076fd439f"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        하나 바라는 점이 생겼습니다그것은 바로 성숙하고 의연하게 살아갈수 있는 인프피가 되...\n",
              "1        관계성 + 주관적 생각, 느낌.현실에서 만난 사람들 대상.NT NF SJ SP순.E...\n",
              "2        인프피로 바뀌었네요요새 외출을 못한 탓인가봐요과거의 저를 만났더라면 서로 비유법으로...\n",
              "3        ​설명이 인프피 같지는 않네요?! 제 설명이 tj느낌..?다른 인프피분들은 건축학과...\n",
              "4                                            ​​​​야근 당첨​​​​\n",
              "                               ...                        \n",
              "24905    저랑 제 연인이 둘 다 isfj 에요.사귄지는 이제 280일 정도 됐어요!​서로 잘...\n",
              "24906    어떤 사랑을 하고 계신가요?가슴 뛰고 설레는 사랑?편안하고 아낌받는 사랑?​난 아직...\n",
              "24907                                                  NaN\n",
              "24908    ENTJ(사촌1, ENFP동생, 성인)😎ENFP(사촌2, ENTJ누나, 성인)😈IN...\n",
              "24909    ENFP.... 새삼 느끼지만 그들에게선 부드러운 카리스마가 느껴집니다.뭐랄까, 사...\n",
              "Name: posts, Length: 24910, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLv51u3dXlin"
      },
      "source": [
        "y_train = data['I-E'][train_index].values\r\n",
        "y_test = data['I-E'][test_index].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo0rZOhjVYbJ"
      },
      "source": [
        "## 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVTRYc0pMD01",
        "outputId": "5b7b953c-0edc-4978-d020-0b7b2bb81b11"
      },
      "source": [
        "sentences = strat_train_set['posts']\r\n",
        "sentences[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    하나 바라는 점이 생겼습니다그것은 바로 성숙하고 의연하게 살아갈수 있는 인프피가 되...\n",
              "1    관계성 + 주관적 생각, 느낌.현실에서 만난 사람들 대상.NT NF SJ SP순.E...\n",
              "2    인프피로 바뀌었네요요새 외출을 못한 탓인가봐요과거의 저를 만났더라면 서로 비유법으로...\n",
              "3    ​설명이 인프피 같지는 않네요?! 제 설명이 tj느낌..?다른 인프피분들은 건축학과...\n",
              "4                                        ​​​​야근 당첨​​​​\n",
              "5    1학년 때 저 혼자서 무지 친하다고 생각했던 친구가 둘 있었는데,(동아리...)제가...\n",
              "6    현실에서 피자 먹으면서 얘기 나누고 싶은데 코로나는 언제 잠잠해질까요...ㅠ​온라인...\n",
              "7                         눈인증이 유행인가요?저도 같이 눈도장 찍고 갑니다❤\n",
              "8    INTJ : 귀찮INTP : 귀찮INFP : 귀찮INFJ : 귀찮ENTJ : 귀찮E...\n",
              "9    갑자기 생각나서 풀어 보는 경험담입니다.​결혼 후 3년 정도 지나고 아내의 친구들과...\n",
              "Name: posts, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np741MDqVehg",
        "outputId": "e07bda35-feff-40e2-f448-91053be9a764"
      },
      "source": [
        "# BERT의 입력 형식에 맞게 변환\r\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\r\n",
        "sentences[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 하나 바라는 점이 생겼습니다그것은 바로 성숙하고 의연하게 살아갈수 있는 인프피가 되고 싶다..모든게 날것 그대로 였던 20대때는 참 많이 기쁘기도 행복하기도 슬프기도 절망스러웠기도 했던 나날의 연속이였어요내가 어디에 발을 내딛고 있는지어디에 중심을 서고 있는지두려움과 소용돌이 치는 감정 안에서누구나 봐도 항상 불안정하고 위태로워 보였죠예민한 감정과 소용돌이 치는 마음들이힘들었지만 한편으론 나는 특별하다는 나르시즘에 갖혀 평범하게 살아가는 사람들의 가치를 깨닫지 못했어요우울증과 세상에 대한 두려움과 기피로 가득했던 사회생활을 전혀 할수 없을것만 같았던 저는어느새 INFP라는 프레임의 껍질에서 나와서 더러 사람들과 같은 평범하게 일을 하며 사는 길을 택했습니다감정에 덜 예민해지는게 나를 잃는것은 아닌지평범하게 일하면서 지내는게 내 영혼을 잠재우는게 아닌지걱정도 됐지만여리고 보호받아야만 하는 자아 이미지 상에서 벗어나감정에 의연해지고 성숙해 지고 싶었습니다우연인지 몰라도테스트 결과도 전이였으면 보호받아야 하는 여린 이미지가 나왔을 법도 한데지금은 좀더 강해진 모습이 투영된 모습이 나왔네요..자리가 사람을 만든다고전혀 변할수 없을거 같던 저도나이가 들고 사회적으로 아랫사람도 거느려야 하는 입장이 되니눈물많고 여리던 인프피의 모습에서만 머무르는것도 아니더군요..전에는 날 것 그대로의 감정 풍부한 저의 모습만이 제 모습이라고 믿고 살았지만살면서 다듬어지고 의연해지는게 인프피인 저에겐 예상치 못한 변화가 되었습니다마음적으로 힘들어하는 인프피들 아마 많을거에요..이세상이 인프피로서 적응하기가 그렇게 보드랍지가 못하니까요그렇다고 해서 예민하고 우울하고 슬픈 모습만이 전부이진 않을테니 시간이 지나면서 성숙해지고 다듬어 진다고 믿어보는것도 나쁘지 않을거 같아요정말 오랫만에 이런 글을 쓰는데..날것 그대로의 인프피도 매력 충만하지만 ^^;마음에 상처에 잠식 당하지 않는 성숙한 인프피의 모습이 되고 싶어요 [SEP]',\n",
              " '[CLS] 관계성 + 주관적 생각, 느낌.현실에서 만난 사람들 대상.NT NF SJ SP순.ENFJ ESFP 아직까지 데이터 없음-NT-INTP들: 성향과 상태에 따라 약간씩 다르지만 대게 별 적대감 없이 지내는 듯. 서로 그닥 터치 안 함. 코드 맞으면 서로 행복하게 지낼 수 있다ㅋㅋ 이들 중 한 명에게서 같이 살자는 얘기가 나왔으나 거절했다.INTJ들: 좋다. 그런데 유리같다. 내가 생각나는 대로 말 뱉었다간 기스날까봐 무섭다. 자꾸 싸우는 장면이 연상된다. 그래선지 무척 가까이하고싶으면서도 유난히 선을 지키게되는 유형. 생각해보면 내가 알게모르게 상처 많이 줬을 것 같은데 미안하다.ENTP들: 편하고 재밌다. 자신감에 찬 모습도 승부욕에 찬 모습도 다 좋음ㅋㅋ 다만 내 상태 안 좋을 때만큼은 건들지 말았으면 한다.ENTJ들: 주로 상대쪽에서 좋게 평가해주는데 이에 대한 응대를 어떻게 해야할지를 모르겠다. 대개 관계가 애매하다.-NF-INFP들: 정말.. 정 많은 유형. 그러나 어느 순간 멀어져있음. 나중에 살펴보면 인사를 못 받아줬다거나.. 뭐 그런 전적들이 있다. \"보이는 것보다 너를 싫어하지 않음\"을 내게 써붙이고 만나고싶다. 고마운 것도 미안한 것도 많다.INFJ: 한 분 계셨는데 자상하고 배려심 넘치셨다. 개그코드도 잘 맞았는데 결국 친해지진 않았다. (내가 그렇지 뭐..) 왜인지 내가 본인을 싫어하는 것으로 추측하고 미리 상처받아 계셨다. 거짓말탐지기를 가져오셔서 \\'안 싫어함-진실\\' 판결을 얻어내고도 미심쩍은 모습이었다.ENFP들: 진짜 살면서 만났던 녀석 중 제일 웃기고 특이한 넘들이었던 부담스러운 넘들. 하지만 정말 자유분방하고 특이했다.. 인상깊었고 마찬가지로 부담스러웠기 때문에 깊게 엮이고 싶진 않았다. (자유분방해서 깊게 엮일 것 같지도 않았다.) 상처도 은근 잘 받는 것 같았다. 이 분들도 그냥 휙 돌아서는 게 있던데 뭐 그냥 냅두고있다. 어떻게 처신하던 다 좋으니 상처받지 말았으면 좋겠다ENFJ: 안 만나봄. 만나면 내가 유난히 못 갖춘 면(;)에 동경하게 될 것 같다-SJ-ISTJ: 성실하고 신중하다. 흔한 유형이라는데 의외로 내 주변에 많이 없었다. 내가 만난 ISTJ는 극강의 겸손함을 보여줬었다. Si유형들이 으레 그렇듯 세심하고 깔끔한 일처리에 강세를 보인다.ISFJ들: 친구로 있을 땐 꽤 괜찮다. ISFJ가 I 중에 가장 사회적이라는 내용을 어디서 본 기억이 난다. 그답게 그들 주위로는 사람들이 몰리더라. 정작 본인들은 피곤해하고 부담스러워하며 그 사람들을 열심히 쳐낸다. 주변에 그냥 특유의 편안~한 분위기가 조성되어있다. 입담 좋고 상황묘사를 상당히 잘 한다는 공통점이 있었다. 지금은 독거노인의 네비게이션으로 활동하고있다. \"내가 길 찾을까?\" 하자 한결같이 반응들이 \\'아니다\\', \\'넌 가만히 있어라\\', \\'그냥 자신이 하겠다\\'며 열정적이었다. 네비게이션이 적성에 잘 맞나보다.ESFJ들: \"시험기간되면 너무 외로워서 힘들더라\" 한 ESFJ가 독거노인에게 토로했던 말이다. 이를 들은 독거노인은 \\'세상에 이런 사람도 존재하는구나\\'를 새삼 깨닫게된다. 크게 트러블은 없으나 이들이 가끔 썰이나 고민상담을 털어놓으면 독거노인의 CPU엔 과부하가 걸린다. (이를 본 ISFP, 평범한 고민인데 너무 이해할 수 없다는 표정으로 쳐다보는 것이 아니냐며 웃는다) 물론 반대의 경우도 존재한다.ESTJ: 딱 한 명 만났는데 생각보다 잘 맞았다. 내게 과거사나, 현재 관심가는 사람 등 뭔가 스스럼 없이 털어놓는 모습을 보였다. 내가 캐치할 수 없던 부분을 지적해줘서 많이 배워갔고(고맙다), 이 사람.. 생각보다 정이 많았다.-SP-ISTP: 편하고 잘 맞았다. 까면서 노는 데 주로 내가 까이는 쪽. 같이 살자는 얘기가 나왔으나 거절했다.ISFP: 잘 맞는 친구. 내 쪽에서 같이 살자고 권유중이다.ESTP들: 약간 서로 어려워하는 듯. 나는 저쪽에서 치는 장난이 어색하고 저쪽은 이유는 모르겠으나 날 어색해하는 건 확실하다. 직접적으로 교류를 하기보다 그냥 노는 걸 지켜보는 편이 더 재밌다. 공통 대화주제를 찾기가 어렵다. ESFP: 만난 적 없다. 만나면 희한할 것 같다.ENFJ ESFP 어떻던가요? ㅋㅋ [SEP]',\n",
              " '[CLS] 인프피로 바뀌었네요요새 외출을 못한 탓인가봐요과거의 저를 만났더라면 서로 비유법으로 대화했겠죠?? [SEP]',\n",
              " '[CLS] \\u200b설명이 인프피 같지는 않네요?! 제 설명이 tj느낌..?다른 인프피분들은 건축학과 나오시던데.. [SEP]',\n",
              " '[CLS] \\u200b\\u200b\\u200b\\u200b야근 당첨\\u200b\\u200b\\u200b\\u200b [SEP]',\n",
              " '[CLS] 1학년 때 저 혼자서 무지 친하다고 생각했던 친구가 둘 있었는데,(동아리...)제가 그 동아리를 떠나게 된 이후로, 그 집단과 더이상 섞이는건 힘들것 같아서, 그 친구들과도 연락을 끊게 됐어요...그러다가....엊그저께 그 친구들이 갑자기 생각나서 연락을 하게 됐죠...연락처를 따는게 그렇게 쉬울줄은 몰랐습니다.-_- 역시 용기만 있으면 된다?ㅋㅋㅋㅋ오랜만에 전화를 했더니... 다시 1학년 때로 회춘한 기분이 들더군요 ㅋㅋㅋㅋㅋ그러다가... 진지하게 이야기가 나왔네요...\"음, 난 지금까지 가장 친하다고 생각했던 친구는 너였다.\"라고 말했더니,,,\"정말??!?! 헤헷 좋네ㅋㅋ\"라고 반응이 오더군요 ㅋㅋ... 그러면서 이런저런 이야기가 나왔습니다... 제가 스스로 만들어낸 저의 부정적인 자아 이미지 때문에그 친구에게 안좋은 인상만 남길 것 같아서 접근하지 못한 것이 급 후회의 쓰나미가 되어 밀려들어오더군요...ㅠㅠ요지를 적자면...보통, 남자와 여자가 사귀기 시작하면, 가급적 타 남자는 여자와 가급적 소통하지 않음으로써 오해를 최소한 줄여야 한다.라고 생각하고 있었던거였죠...그것 때문에 괜히 그 남자친구랑 일이 복잡하게 될까봐... 차마 말은 못 걸겠고 =ㄴ=.... 그랬던 이야기들을 했었습니다...그 친구도 절 친구로 생각하고 있었기 때문에 실망을 많이 하더군요 ㄱ-....역시... 사람간에 자기 마음속에 있는 말을 해야할 때는 해야하는거구나 싶었습니다...실제적으로 돌아오는 반응이란게 어떤건지 또 내가 생각하는 것과 다를 수 있다는걸 깨닫게 됐네요...쩝... 대학생활에서 그나마 외롭지 않게 친구 한명과 소통할 수\\xa0있었겠구나...싶은 마음이 드니까, 괜히 마음도 아프고 그렇군요... ㄱ-....앞으론... 친구라 생각하면, 제 마음을 서슴없이 보여줘야겠습니다.-_-;;;내가 상대에 대해 어떻게 생각하고 있는지, 그리고 상대는 나를 어떻게 생각하고 있는지... [SEP]',\n",
              " '[CLS] 현실에서 피자 먹으면서 얘기 나누고 싶은데 코로나는 언제 잠잠해질까요...ㅠ\\u200b온라인에서 할 수 있는 카페활동은 거의 다 해봐서 이젠 얼굴 보는 일만 남은 듯 ㅇㅅㅇ [SEP]',\n",
              " '[CLS] 눈인증이 유행인가요?저도 같이 눈도장 찍고 갑니다❤ [SEP]',\n",
              " '[CLS] INTJ : 귀찮INTP : 귀찮INFP : 귀찮INFJ : 귀찮ENTJ : 귀찮ENTP : 귀찮ENFJ : 귀찮ENFP : 귀찮ISTJ : 귀찮ISTP : 귀찮ISFP : 귀찮ISFJ : 귀찮ESTJ : 귀찮ESTP : 귀찮ESFP : 귀찮ESFJ : 귀찮--------------------------------------------------------------------그러므로 난 아오지 탄광으로...(?!!??!!) [SEP]',\n",
              " '[CLS] 갑자기 생각나서 풀어 보는 경험담입니다.\\u200b결혼 후 3년 정도 지나고 아내의 친구들과 함께 술을 마시던 날 친구 중 누군가 묻더라구요.\\u200b그런데 너는 왜 남편하고 결혼할 생각을 했어?순간 집중되는 분위기!\\u200b속으로 멋진 답변을 잠깐 기대했다가, 아내는 현실적인 면이 지극히 강해서7년을 만났으니까 그냥 결혼한 거지 뭐ㅎ 이런 대답이 나오겠지...\\u200b아내는 누구한테랄것도 없이 해맑게 웃으며, 조금도 망설이지 않고 말했습니다.\\u200b\\u200b\"이 사람이 없으면 못 사니까!\"\\u200b\\u200b천년을 더 산다 해도 이보다 멋진 대답을 들을 수 있을까요?아직도 이 말을 들었던 순간이 어제 일처럼 기억납니다.\\u200b [SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "a1529816ba2040aebb0f1612896569ac",
            "f2ae62ffc3a24e8ba06b29c6b769ca51",
            "82324519eca040fd8072960ea38ba1ef",
            "d4bb11593988482db4fd1df0cf127968",
            "fe6e6dbec63f401598b9d989113972e0",
            "237d73a2663248e49c561a5e6d91c49c",
            "3203a0a065c843f1b62a91e3f1491484",
            "2c94087184de430684f656fc3e231335"
          ]
        },
        "id": "Pw3sMMPZVg0i",
        "outputId": "a71c0a27-919d-412c-a88f-fcb79c040723"
      },
      "source": [
        "# BERT의 토크나이저로 문장을 토큰으로 분리\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\r\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\r\n",
        "\r\n",
        "print (sentences[0])\r\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1529816ba2040aebb0f1612896569ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[CLS] 하나 바라는 점이 생겼습니다그것은 바로 성숙하고 의연하게 살아갈수 있는 인프피가 되고 싶다..모든게 날것 그대로 였던 20대때는 참 많이 기쁘기도 행복하기도 슬프기도 절망스러웠기도 했던 나날의 연속이였어요내가 어디에 발을 내딛고 있는지어디에 중심을 서고 있는지두려움과 소용돌이 치는 감정 안에서누구나 봐도 항상 불안정하고 위태로워 보였죠예민한 감정과 소용돌이 치는 마음들이힘들었지만 한편으론 나는 특별하다는 나르시즘에 갖혀 평범하게 살아가는 사람들의 가치를 깨닫지 못했어요우울증과 세상에 대한 두려움과 기피로 가득했던 사회생활을 전혀 할수 없을것만 같았던 저는어느새 INFP라는 프레임의 껍질에서 나와서 더러 사람들과 같은 평범하게 일을 하며 사는 길을 택했습니다감정에 덜 예민해지는게 나를 잃는것은 아닌지평범하게 일하면서 지내는게 내 영혼을 잠재우는게 아닌지걱정도 됐지만여리고 보호받아야만 하는 자아 이미지 상에서 벗어나감정에 의연해지고 성숙해 지고 싶었습니다우연인지 몰라도테스트 결과도 전이였으면 보호받아야 하는 여린 이미지가 나왔을 법도 한데지금은 좀더 강해진 모습이 투영된 모습이 나왔네요..자리가 사람을 만든다고전혀 변할수 없을거 같던 저도나이가 들고 사회적으로 아랫사람도 거느려야 하는 입장이 되니눈물많고 여리던 인프피의 모습에서만 머무르는것도 아니더군요..전에는 날 것 그대로의 감정 풍부한 저의 모습만이 제 모습이라고 믿고 살았지만살면서 다듬어지고 의연해지는게 인프피인 저에겐 예상치 못한 변화가 되었습니다마음적으로 힘들어하는 인프피들 아마 많을거에요..이세상이 인프피로서 적응하기가 그렇게 보드랍지가 못하니까요그렇다고 해서 예민하고 우울하고 슬픈 모습만이 전부이진 않을테니 시간이 지나면서 성숙해지고 다듬어 진다고 믿어보는것도 나쁘지 않을거 같아요정말 오랫만에 이런 글을 쓰는데..날것 그대로의 인프피도 매력 충만하지만 ^^;마음에 상처에 잠식 당하지 않는 성숙한 인프피의 모습이 되고 싶어요 [SEP]\n",
            "['[CLS]', '하', '##나', '바', '##라는', '점', '##이', '생', '##겼', '##습', '##니다', '##그', '##것', '##은', '바로', '성', '##숙', '##하고', '의', '##연', '##하게', '살', '##아', '##갈', '##수', '있는', '인', '##프', '##피', '##가', '되고', '싶', '##다', '.', '.', '모든', '##게', '날', '##것', '그대로', '였', '##던', '20', '##대', '##때', '##는', '참', '많이', '기', '##쁘', '##기도', '행', '##복', '##하기도', '슬', '##프', '##기도', '절', '##망', '##스', '##러', '##웠', '##기도', '했', '##던', '나', '##날', '##의', '연속', '##이', '##였', '##어', '##요', '##내', '##가', '어', '##디', '##에', '발', '##을', '[UNK]', '있는', '##지', '##어', '##디', '##에', '중', '##심을', '서', '##고', '있는', '##지', '##두', '##려', '##움', '##과', '소', '##용', '##돌', '##이', '치', '##는', '감', '##정', '안', '##에서', '##누', '##구', '##나', '봐', '##도', '항', '##상', '불', '##안', '##정', '##하고', '위', '##태로', '##워', '보', '##였', '##죠', '##예', '##민', '##한', '감', '##정', '##과', '소', '##용', '##돌', '##이', '치', '##는', '마', '##음', '##들이', '##힘', '##들', '##었지만', '한편', '##으', '##론', '나는', '특', '##별', '##하다', '##는', '나', '##르', '##시', '##즘', '##에', '갖', '##혀', '평', '##범', '##하게', '살', '##아', '##가는', '사', '##람', '##들의', '가', '##치를', '깨', '##닫', '##지', '못', '##했', '##어', '##요', '##우', '##울', '##증', '##과', '세', '##상', '##에', '대한', '두', '##려', '##움', '##과', '기', '##피', '##로', '가', '##득', '##했던', '사', '##회', '##생', '##활', '##을', '전', '##혀', '할', '##수', '없', '##을', '##것', '##만', '같', '##았', '##던', '저', '##는', '##어', '##느', '##새', 'IN', '##F', '##P', '##라는', '프', '##레', '##임', '##의', '껍', '##질', '##에서', '나', '##와', '##서', '더', '##러', '사', '##람', '##들과', '같은', '평', '##범', '##하게', '일을', '하며', '사', '##는', '길', '##을', '택', '##했', '##습', '##니다', '##감', '##정에', '덜', '예', '##민', '##해', '##지는', '##게', '나', '##를', '잃', '##는', '##것', '##은', '아닌', '##지', '##평', '##범', '##하게', '일', '##하면서', '지', '##내는', '##게', '내', '영', '##혼', '##을', '잠', '##재', '##우', '##는', '##게', '아닌', '##지', '##걱', '##정', '##도', '됐', '##지만', '##여', '##리고', '보', '##호', '##받', '##아', '##야', '##만', '하는', '자', '##아', '이미', '##지', '상', '##에서', '벗', '##어', '##나', '##감', '##정에', '의', '##연', '##해', '##지고', '성', '##숙', '##해', '지', '##고', '싶', '##었', '##습', '##니다', '##우', '##연', '##인', '##지', '몰', '##라', '##도', '##테', '##스트', '결과', '##도', '전', '##이', '##였', '##으면', '보', '##호', '##받', '##아', '##야', '하는', '여', '##린', '이미', '##지가', '나', '##왔', '##을', '법', '##도', '한', '##데', '##지', '##금', '##은', '좀', '##더', '강', '##해', '##진', '모', '##습', '##이', '투', '##영', '##된', '모', '##습', '##이', '나', '##왔', '##네', '##요', '.', '.', '자', '##리가', '사', '##람', '##을', '만든', '##다고', '##전', '##혀', '변', '##할', '##수', '없', '##을', '##거', '같', '##던', '저', '##도', '##나', '##이가', '들', '##고', '사', '##회', '##적으로', '아', '##랫', '##사', '##람', '##도', '거', '##느', '##려', '##야', '하는', '입', '##장이', '되', '##니', '##눈', '##물', '##많', '##고', '여', '##리', '##던', '인', '##프', '##피', '##의', '모', '##습', '##에서', '##만', '머', '##무', '##르는', '##것', '##도', '아', '##니', '##더', '##군', '##요', '.', '.', '전에', '##는', '날', '것', '그대로', '##의', '감', '##정', '풍', '##부', '##한', '저', '##의', '모', '##습', '##만', '##이', '제', '모', '##습', '##이', '##라고', '믿', '##고', '살', '##았', '##지만', '##살', '##면서', '다', '##듬', '##어', '##지고', '의', '##연', '##해', '##지는', '##게', '인', '##프', '##피', '##인', '저', '##에', '##겐', '예', '##상', '##치', '못', '##한', '변', '##화가', '되', '##었', '##습', '##니다', '##마', '##음', '##적으로', '힘', '##들어', '##하는', '인', '##프', '##피', '##들', '아', '##마', '많', '##을', '##거', '##에', '##요', '.', '.', '이', '##세', '##상이', '인', '##프', '##피', '##로서', '적', '##응', '##하기', '##가', '그', '##렇게', '보', '##드', '##랍', '##지가', '못', '##하', '##니', '##까', '##요', '##그', '##렇', '##다고', '해', '##서', '예', '##민', '##하고', '우', '##울', '##하고', '슬', '##픈', '모', '##습', '##만', '##이', '전', '##부', '##이', '##진', '않', '##을', '##테', '##니', '시', '##간이', '지', '##나', '##면서', '성', '##숙', '##해', '##지고', '다', '##듬', '##어', '진', '##다고', '믿', '##어', '##보', '##는', '##것', '##도', '나', '##쁘', '##지', '않', '##을', '##거', '같', '##아', '##요', '##정', '##말', '오', '##랫', '##만', '##에', '이런', '글', '##을', '쓰', '##는데', '.', '.', '날', '##것', '그대로', '##의', '인', '##프', '##피', '##도', '매', '##력', '충', '##만', '##하지', '##만', '^', '^', ';', '마', '##음', '##에', '상', '##처', '##에', '잠', '##식', '당', '##하지', '않는', '성', '##숙', '##한', '인', '##프', '##피', '##의', '모', '##습', '##이', '되고', '싶', '##어', '##요', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeFD22ELWRr1",
        "outputId": "f6db6434-ec12-43e3-b15a-6bd79d377a4a"
      },
      "source": [
        "# 라벨 추출\r\n",
        "labels = strat_train_set['I-E'].values\r\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b9s0c-QWbcP",
        "outputId": "d7182626-cde6-4bec-c2c7-dcf1f79721f5"
      },
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이\r\n",
        "MAX_LEN = 128\r\n",
        "\r\n",
        "# 토큰을 숫자 인덱스로 변환\r\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "\r\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\r\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "input_ids[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,   9952,  16439,   9318,  60362,   9668,  10739,   9420,\n",
              "       118637, 119081,  48345,  78136, 118627,  10892,  71433,   9434,\n",
              "       119063,  12453,   9637,  25486,  17594,   9408,  16985, 101202,\n",
              "        15891,  13767,   9640,  28396,  97146,  11287,  66674,   9495,\n",
              "        11903,    119,    119,  25701,  14153,   8985, 118627, 110589,\n",
              "         9573,  23990,  10197,  14423, 118832,  11018,   9735,  47058,\n",
              "         8932, 119022,  27792,   9966,  70915,  68100,   9479,  28396,\n",
              "        27792,   9666,  89292,  12605,  30873, 119172,  27792,   9965,\n",
              "        23990,   8982,  41919,  10459, 100208,  10739, 119147,  12965,\n",
              "        48549,  31605,  11287,   9546,  48446,  10530,   9323,  10622,\n",
              "          100,  13767,  12508,  12965,  48446,  10530,   9694,  86904,\n",
              "         9425,  11664,  13767,  12508, 118802,  26737, 119169,  11882,\n",
              "         9448,  24974, 118794,  10739,   9779,  11018,   8848,  16605,\n",
              "         9521,  11489, 118751,  17196,  16439,   9363,  12092,   9959,\n",
              "        14871,   9368,  34951,  16605,  12453,   9619,  85386,  69592,\n",
              "         9356, 119147, 119217,  96279,  36553,  11102,   8848,  16605])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQjJvVRzWgjc",
        "outputId": "51eab7f6-db8b-4e15-9d6c-c31121e0128f"
      },
      "source": [
        "# 어텐션 마스크 초기화\r\n",
        "attention_masks = []\r\n",
        "\r\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\r\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\r\n",
        "for seq in input_ids:\r\n",
        "    seq_mask = [float(i>0) for i in seq]\r\n",
        "    attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "print(attention_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vww3Fy0ZWusj",
        "outputId": "dc8f0403-678a-4cab-a3bb-68a409765fa5"
      },
      "source": [
        "# 훈련셋과 검증셋으로 분리\r\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\r\n",
        "                                                                                    labels, \r\n",
        "                                                                                    random_state=2018, \r\n",
        "                                                                                    test_size=0.1)\r\n",
        "\r\n",
        "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\r\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \r\n",
        "                                                       input_ids,\r\n",
        "                                                       random_state=2018, \r\n",
        "                                                       test_size=0.1)\r\n",
        "\r\n",
        "# 데이터를 파이토치의 텐서로 변환\r\n",
        "train_inputs = torch.tensor(train_inputs)\r\n",
        "train_labels = torch.tensor(train_labels)\r\n",
        "train_masks = torch.tensor(train_masks)\r\n",
        "validation_inputs = torch.tensor(validation_inputs)\r\n",
        "validation_labels = torch.tensor(validation_labels)\r\n",
        "validation_masks = torch.tensor(validation_masks)\t\t\t\t\r\n",
        "\r\n",
        "print(train_inputs[0])\r\n",
        "print(train_labels[0])\r\n",
        "print(train_masks[0])\r\n",
        "print(validation_inputs[0])\r\n",
        "print(validation_labels[0])\r\n",
        "print(validation_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([   101,   8924, 118729,   9069, 119276,  10739,  17342,  12092,   9551,\n",
            "         37819,   9583,  12692,  13764,    100,   8982,  10892,    100,   9583,\n",
            "         62211,   9495,  12965,  12424,  11903,  14040,   9574,  14871,   9924,\n",
            "         38696,  14523,  48549,    119,    119,    119,   9330,  43962,  10622,\n",
            "          9041,  12692,  14153,   9965,  54141,  25503,   9074,   9356,  12310,\n",
            "          9685,  11664,  10017,  27023,  67527,  10892,   9077,  35506,  77884,\n",
            "         48549,    119,   9011,  10739,  41605,   9095,  30858,  14871,   9944,\n",
            "         56645,  86732,  21069,    131,  11025,  36210,  24017, 100699,    117,\n",
            "          9638,   9095,  30858,  70969,   8934,  31728,    121,  57030,   9645,\n",
            "         48345,    119,   9358,   9574,  14871,  15303,   8845, 119205, 118649,\n",
            "         11664,  11287,   9928,  48533,  16855,   9647, 119081,  48345,    119,\n",
            "         31191,  10622,   9357,  12945,  14523,  16323,  24982,  48549,    119,\n",
            "           102,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "tensor([   101,   9546,  93119,  12424,  16323, 118985,  10530,   9638,  82838,\n",
            "         97802,  25685,  28911,  78705,  11261,  78123, 118671,  48549,    100,\n",
            "          8924,  17730,  12092,   9781,  11102,   9785,  17196,  27023,    100,\n",
            "          9025, 119118,  41850,    119,    119,    119,    100,   8924,  56710,\n",
            "          8870,  18392, 118671,  48549,    106,    106,    106,    106,    106,\n",
            "           106,    106,    100,   9477, 118912, 119401,  10739,  16985,  25503,\n",
            "         17342,  12424,  12605, 118912, 119401,  12030,   9781,  17196,  20173,\n",
            "         62200,   9654,   9545,  29669,    100,    100,   9251,  22440,  91069,\n",
            "          8982,   9597, 118884,  14153,   9521,  14523, 119222,  80046,    100,\n",
            "           106,    106,    106,  80956,    106,    106,    106,    106,  10016,\n",
            "           119,    119,    119,    100,    102,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0])\n",
            "tensor(1)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1N9qh7xZJLk"
      },
      "source": [
        "# 배치 사이즈\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\r\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\r\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\r\n",
        "train_sampler = RandomSampler(train_data)\r\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n",
        "\r\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\r\n",
        "validation_sampler = SequentialSampler(validation_data)\r\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PonZdpwrZOms"
      },
      "source": [
        "# 전처리 - 테스트셋"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC1FKVbGZNbZ",
        "outputId": "811a1a1c-e71c-4bde-d26e-575706d4a656"
      },
      "source": [
        "# 리뷰 문장 추출\r\n",
        "sentences = strat_test_set['posts']\r\n",
        "sentences[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    ​어제 저녁 8-9시쯤에 졸려서 잤는데 새벽 6시 50분에 일어났다가, 다시 자니 ...\n",
              "1    그정도까진 아닌데 참 극단적으로 나오네요 ㅋㅋ 그래도 저번에 CCCCC 나온 것 보...\n",
              "2    Entj여러분, 반복된 같은 행동 잘 질려하시나요?반복해서 꾸준히 하는 게 좋다는데...\n",
              "3    평일엔 정신없이 바쁘더니만..주말인 어제와 오늘은 정말 하염없이 한가하네요..마트라...\n",
              "4    남에게 관대하고 자기자신에게 엄격한 사람과남에게 엄격하고 자기자신에게 관대한 사람이...\n",
              "5    주인공이 압도적인 힘으로 다 뚜까패는게 너무 좋은데 싫어하시는 분들있으신가요?뭔가 ...\n",
              "6    저희 조는 파자마 스타일로 촬영했거든여근데 인형도 챙기고 왔는데하필 인형이 하츠네 ...\n",
              "7                                                  ​원본\n",
              "8    드디어 글로 정리하는데 성공ㅠㅠ인간은 과거의 영화를 그리워하는 것이 아니다.미래를 ...\n",
              "9    infp 썸남이 고백을 2달 넘게 준비만 하고 있어요...그 사이에 뭐 카톡이나 데...\n",
              "Name: posts, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ion4zSwaZWzq",
        "outputId": "e346841a-adda-41fe-a88a-8c5742849437"
      },
      "source": [
        "# BERT의 입력 형식에 맞게 변환\r\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\r\n",
        "sentences[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] \\u200b어제 저녁 8-9시쯤에 졸려서 잤는데 새벽 6시 50분에 일어났다가, 다시 자니 8시에 일어났네요 ㅎㅎ생각보다 많이 피곤했나 봐요 ㅋㅋㅋ 아직도 약간 졸려요\\u200b심심ㅎ9서 FBTI 패션 성향 테스트 해봤는데\\u200b\\u200b이거 생각보다 맞는 거 같아요 ㅋㅋ유형별로 맞는 옷, 어울리는 옷으로 정리해둔 게 있던데 보자마자 넘 예쁘다는 생각이 들어 스크롤 내리는 중\\u200b시작하기fbti.elandmall.com\\u200b\\u200b [SEP]',\n",
              " '[CLS] 그정도까진 아닌데 참 극단적으로 나오네요 ㅋㅋ 그래도 저번에 CCCCC 나온 것 보다는 나으려나요 [SEP]',\n",
              " '[CLS] Entj여러분, 반복된 같은 행동 잘 질려하시나요?반복해서 꾸준히 하는 게 좋다는데,\\u200b저는 반복된 행동을 계속하는 걸 잘 질려해요.예를 들면 운동도 유산소 동작 3회 반복이면, 2회 같은 동작, 1회는 다른 동작으로 해야하고요.\\u200b운동 종목도 수영, 달리기, 배드민턴 등 섞어서 해요 꾸준히 오래하고여..\\u200b언어 공부도 예를 들어 미드로 한다고 하면 다른 종류 섞어서 들어야 꾸준히 해요...\\u200b뭐든 같은 걸 계속하려면 질려해서 섞어서 해야해요.이게 entj가 단기 목표에만 강해서 그런걸까요??\\u200b일할때는 어떠신가요? 저는 장기 프로젝트는 지쳐서 단기 프로젝트가 잘 맞는 것 같아요..\\u200bentj가 지치지 않고 목표를 잘 달성할 수 있는여러분의 노하우를 알려주실 수 있나요?눈앞에 목표나 달성수치가 안보이면 슬럼프가 자주 오는 것 같아요! [SEP]',\n",
              " '[CLS] 평일엔 정신없이 바쁘더니만..주말인 어제와 오늘은 정말 하염없이 한가하네요..마트라 앞에 사람은 엄청 많은데.. 핸드폰은 아무 관심따위 ㅋㅋㅋㅋㅋㅋㅋㅋㅋ진심 너무 심심해요 ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ뉴스도 다 봤고.. 이거저거 하는거도 한계..어제 오늘 인터넷만 15시간은 하는모양 ㅠㅠ 뭘해야 이 심심함이 가실까요.. -_-;; [SEP]',\n",
              " '[CLS] 남에게 관대하고 자기자신에게 엄격한 사람과남에게 엄격하고 자기자신에게 관대한 사람이 있는데전 남에게 관대하고 자기자신에게 너무 엄격한 것 같아요.예를 들어 친구가 약속시간 늦어도 별로 신경쓰지 않는데(지속되면 손절 카운트 세긴 하지만) 제가 늦으면 제 자신이 싫어져요.저 자신에게 엄격해서 발전할 수 있다면 괜찮은데, 생각하다보면 다 부정적인 생각만 하고 자기혐오에 빠지는 것 같아요.\\u200b여러분은 둘 중 어느쪽인 것 같나요? [SEP]',\n",
              " '[CLS] 주인공이 압도적인 힘으로 다 뚜까패는게 너무 좋은데 싫어하시는 분들있으신가요?뭔가 주인공이 지면 내가 불안함... [SEP]',\n",
              " \"[CLS] 저희 조는 파자마 스타일로 촬영했거든여근데 인형도 챙기고 왔는데하필 인형이 하츠네 미쿠 인형이라서ㅋㅋㅋㅋㅋㅋ\\u200b그래서 제 친구한테 '이 인형 뭔지 아니?'라고 물어봤더니'이거 유키 미쿠 아니야?' 라고 말했더니 저는 '딩동댕!'이라고 말했어요ㅋㅋㅋㅋㅋ\\u200b근데 약간 외모상으로 일진?(진짜 일진인지는 모름)같이 생긴 애 2명이비웃는거 같더라고요ㅋㅋㅋㅋ\\u200b하지만 전 신경쓰지는 않았습니다\\u200b어차피 제가 모르는 애고 나만의 취향이 있고 심지어저희반에는 캐릭터가 그린 옷을 입고 졸업앨범 찍은 애도 있어서ㅋㅋㅋㅋㅋㅋㅋ(아이돌마스터 멤버 중 하나)(진짜 존경한다 ㄹㅇ)\\u200b이 3가지 이유로 상처 안받음ㅋㅋㅋㅋㅋㅋ신경도 안쓰고\\u200b오늘의 결론:나만의 취향가지고 비웃는 애들은 오타쿠보다 더한거 같다ㅋㅋㅋㅋ\\u200b\\u200b [SEP]\",\n",
              " '[CLS] \\u200b원본 [SEP]',\n",
              " '[CLS] 드디어 글로 정리하는데 성공ㅠㅠ인간은 과거의 영화를 그리워하는 것이 아니다.미래를 그리워하는 것이다.과거에 행복했던 기억들을 한번 떠올려보시길 바란다.그게 단지 그 순간에 행복했던 기억인지, 미래에 대한 기대감, 꿈, 희망이 가득했던 기억인지.전자는 기억이 희미하지만 후자는 강렬하게 남아있을 것이다.\\xa0재밌는 건 그 때 꿈꿨던 세상이 지금이라는 것이다. 물론 아직 그 꿈들이 다 이뤄진 건 아니기 때문에 지금 시점에서 미래이기도 하다.즉, 우리가 그리워하는 건 과거가 아니라 미래인 것이다.앞서 인간은 없는 것을 상상하는 것이 아니라 평행우주의 내가 겪는 일들을 투시하듯이 보는 것이라 했다.인간은 기본적으로 미래를 볼 수 있다. 단지 그 많은 미래들 중 뭐가 실현될지 알 수 없었을 뿐.수많은 평행우주 중 내가 가장 마음에 드는 우주만 선택적으로 구경한 것이 우리가 꿈이라고 말하는 것들인 셈이다.헌데 과학기술이 극한으로 발전하면 소망과 예언의 경계가 무너진다. 원하는 미래를\\xa0 완벽하게 실현할 수 있게 되면 더 이상 꿈도 희망도 미래도 존재하지 않게되는 시점이 온다.인간이 신을 만난 것이 아니라 미래의 자신,정확히는 2050년대의 자신을 본 것이라서 그 이후의 세상은 꿈꿀 수가 없다.2050년대의 내가 모든 평행우주의 나 중 가장 성공한 사람이기 때문에. 인간의 상상력의 한계는 여기서 비롯된다.신을 상상하지 않고 나 자신을 상상했기 때문에.수천년간 대다수 인류는 신이 아니라 2050년의 자기 자신을 꿈꾼 것인지도 모른다.그리고 인간은 과거를 두려워하는 것이지 미래를 두려워하는 게 아니다.과거 트라우마를 안긴 사건이 또 일어나는게 두려울 뿐. [SEP]',\n",
              " '[CLS] infp 썸남이 고백을 2달 넘게 준비만 하고 있어요...그 사이에 뭐 카톡이나 데이트나 그런 것도 없어서 썸이라고 하기에도 애매한 관계인데 제가 3달을 마냥 기다려줬거든요.\\u200b저는 이미 마음을 표현한 상태인데 뭘 그렇게 망설이는지 모르겠어요. 저한테 있지도 않는 남자친구가 있다고 상상하길래 제가 장문의 글로 걔가 추측하고 불안해하던 거 다 설명해줬거든요.\\u200b제가 물어보는건 답은 안 해주는데 저만 혼자 그애가 왜 불안해하고 망설이는지 엿듣고 추측해서 마음 편하게 해주려고 노력했는데 이제 너무 지쳤어요.그래서 왜 그러는지 설명해달라고 제 입장을 쓴 글을 카톡으로 보내고 일부러 얼굴 안 본 지 3주 됐어요.절 너무너무 좋아한다는 게 그애의 뚝딱거리는 행동으로 다 느껴지는데 왜 이러는걸까요. 저만 노력하는 거 같아서 너무 힘들어요. [SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTbRmq1_ZZPm",
        "outputId": "e73603d5-a554-4337-dcda-66d6c613e106"
      },
      "source": [
        "# 라벨 추출\r\n",
        "labels = strat_test_set['I-E'].values\r\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mtIh9HYZdvu",
        "outputId": "78b7b6ac-d1ae-4baf-e633-1dde5c3bb29f"
      },
      "source": [
        "# BERT의 토크나이저로 문장을 토큰으로 분리\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\r\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\r\n",
        "\r\n",
        "print (sentences[0])\r\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] ​어제 저녁 8-9시쯤에 졸려서 잤는데 새벽 6시 50분에 일어났다가, 다시 자니 8시에 일어났네요 ㅎㅎ생각보다 많이 피곤했나 봐요 ㅋㅋㅋ 아직도 약간 졸려요​심심ㅎ9서 FBTI 패션 성향 테스트 해봤는데​​이거 생각보다 맞는 거 같아요 ㅋㅋ유형별로 맞는 옷, 어울리는 옷으로 정리해둔 게 있던데 보자마자 넘 예쁘다는 생각이 들어 스크롤 내리는 중​시작하기fbti.elandmall.com​​ [SEP]\n",
            "['[CLS]', '어', '##제', '저', '##녁', '8', '-', '9', '##시', '##쯤', '##에', '졸', '##려', '##서', '[UNK]', '새', '##벽', '6', '##시', '50', '##분에', '일', '##어', '##났다', '##가', ',', '다시', '자', '##니', '8', '##시', '##에', '일', '##어', '##났', '##네', '##요', '[UNK]', '많이', '피', '##곤', '##했', '##나', '봐', '##요', '[UNK]', '아', '##직', '##도', '약', '##간', '[UNK]', 'F', '##B', '##TI', '패', '##션', '성', '##향', '테', '##스트', '해', '##봤', '##는데', '##이', '##거', '생', '##각', '##보다', '맞', '##는', '거', '같', '##아', '##요', '[UNK]', '맞', '##는', '옷', ',', '어', '##울', '##리는', '옷', '##으로', '정', '##리', '##해', '##둔', '게', '있던', '##데', '보', '##자', '##마', '##자', '넘', '예', '##쁘', '##다는', '생', '##각', '##이', '들어', '스', '##크', '##롤', '내', '##리는', '중', '##시', '##작', '##하기', '##f', '##bt', '##i', '.', 'elan', '##dma', '##ll', '.', 'com', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQrs8r0CZfhx",
        "outputId": "63929681-3379-43d4-e5a2-1c6d25db04ad"
      },
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이\r\n",
        "MAX_LEN = 128\r\n",
        "\r\n",
        "# 토큰을 숫자 인덱스로 변환\r\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "\r\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\r\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "input_ids[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,   9546,  17730,   9663, 118738,    129,    118,    130,\n",
              "        14040, 119244,  10530,   9681,  26737,  12424,    100,   9415,\n",
              "       118984,    127,  14040,  10462, 110355,   9641,  12965,  58813,\n",
              "        11287,    117,  25805,   9651,  25503,    129,  14040,  10530,\n",
              "         9641,  12965, 118718,  77884,  48549,    100,  47058,   9946,\n",
              "       118639, 119424,  16439,   9363,  48549,    100,   9519,  33077,\n",
              "        12092,   9539,  18784,    100,    143,  11274,  72286,   9909,\n",
              "        59095,   9434,  79544,   9866,  34994,   9960, 118991,  41850,\n",
              "        10739,  41521,   9420,  66540,  80001,   9256,  11018,   8863,\n",
              "         8855,  16985,  48549,    100,   9256,  11018,   9588,    117,\n",
              "         9546,  78123,  26344,   9588,  11467,   9670,  12692,  14523,\n",
              "       118804,   8872,  43646,  28911,   9356,  13764,  23811,  13764,\n",
              "         9008,   9576, 119022,  82034,   9420,  66540,  10739,  71568,\n",
              "         9477,  20308, 118882,   8996,  26344,   9694,  14040,  38709,\n",
              "        22440,  10575,  18443,  10116,    119, 105004,  75232,  11231,\n",
              "          119,  10212,    102,      0,      0,      0,      0,      0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eh8ujtTZhGq",
        "outputId": "cf44be9e-cb97-46ad-9e79-2115bc6d5d57"
      },
      "source": [
        "# 어텐션 마스크 초기화\r\n",
        "attention_masks = []\r\n",
        "\r\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\r\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\r\n",
        "for seq in input_ids:\r\n",
        "    seq_mask = [float(i>0) for i in seq]\r\n",
        "    attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "print(attention_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GEE3WxdZipP",
        "outputId": "363f5a16-f3fc-4cb5-decc-e00b5aaddef5"
      },
      "source": [
        "# 데이터를 파이토치의 텐서로 변환\r\n",
        "test_inputs = torch.tensor(input_ids)\r\n",
        "test_labels = torch.tensor(labels)\r\n",
        "test_masks = torch.tensor(attention_masks)\r\n",
        "\r\n",
        "print(test_inputs[0])\r\n",
        "print(test_labels[0])\r\n",
        "print(test_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([   101,   9546,  17730,   9663, 118738,    129,    118,    130,  14040,\n",
            "        119244,  10530,   9681,  26737,  12424,    100,   9415, 118984,    127,\n",
            "         14040,  10462, 110355,   9641,  12965,  58813,  11287,    117,  25805,\n",
            "          9651,  25503,    129,  14040,  10530,   9641,  12965, 118718,  77884,\n",
            "         48549,    100,  47058,   9946, 118639, 119424,  16439,   9363,  48549,\n",
            "           100,   9519,  33077,  12092,   9539,  18784,    100,    143,  11274,\n",
            "         72286,   9909,  59095,   9434,  79544,   9866,  34994,   9960, 118991,\n",
            "         41850,  10739,  41521,   9420,  66540,  80001,   9256,  11018,   8863,\n",
            "          8855,  16985,  48549,    100,   9256,  11018,   9588,    117,   9546,\n",
            "         78123,  26344,   9588,  11467,   9670,  12692,  14523, 118804,   8872,\n",
            "         43646,  28911,   9356,  13764,  23811,  13764,   9008,   9576, 119022,\n",
            "         82034,   9420,  66540,  10739,  71568,   9477,  20308, 118882,   8996,\n",
            "         26344,   9694,  14040,  38709,  22440,  10575,  18443,  10116,    119,\n",
            "        105004,  75232,  11231,    119,  10212,    102,      0,      0,      0,\n",
            "             0,      0])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
            "        0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_We8zBdZkFb"
      },
      "source": [
        "# 배치 사이즈\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\r\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\r\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\r\n",
        "test_sampler = RandomSampler(test_data)\r\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U69_NsAPZmw2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VKhLPheZnBU"
      },
      "source": [
        "# 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biEnsKVUZlkC",
        "outputId": "4d9912a8-8904-4efa-e2ea-8ca4153441a4"
      },
      "source": [
        "# GPU 디바이스 이름 구함\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "\r\n",
        "# GPU 디바이스 이름 검사\r\n",
        "if device_name == '/device:GPU:0':\r\n",
        "    print('Found GPU at: {}'.format(device_name))\r\n",
        "else:\r\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xp9oUo6ZpVa",
        "outputId": "b5f7b2d5-4ec5-4904-82ae-c7b24c0348cf"
      },
      "source": [
        "# 디바이스 설정\r\n",
        "if torch.cuda.is_available():    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "else:\r\n",
        "    device = torch.device(\"cpu\")\r\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "339cab601f554c87b14bb71619a06037",
            "6d7e9282f8b7474b971b40dfb4380301",
            "73d5cb90a8354621966ac1bd11c0f65a",
            "9de5fc3aee354c45940d8b071f3ee51d",
            "63290d34092f481b98f8e2e7a777f4d4",
            "7fa5c76a06f0402bb60492abf0bc8ffd",
            "da632738b3914d04aee960b838dd8a2a",
            "61070751b4c24df896a6b69099633ef1",
            "b8fe4251c906408896814605bfe3b6ed",
            "b2d371163655495d9e45732ad4fab962",
            "3fd4db6f2a374a119acabdd60b963b7f",
            "6673b0766b5c4f26b714a14bfdf49e77",
            "1209b336c2d348f8a15c5cc6265cbf57",
            "05bd8cc22b9444c3a11361621a574a74",
            "32dc52c3f96b45d1bf01ae9ae9e1778a",
            "b1c90489a394488ea95552fc530e534f"
          ]
        },
        "id": "T1zRy5gubXeE",
        "outputId": "e61addd7-9c4a-4a30-8978-0fca4b953916"
      },
      "source": [
        "# 분류를 위한 BERT 모델 생성\r\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\r\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "339cab601f554c87b14bb71619a06037",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8fe4251c906408896814605bfe3b6ed",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDGH2ikEbjEB"
      },
      "source": [
        "# 옵티마이저 설정\r\n",
        "optimizer = AdamW(model.parameters(),\r\n",
        "                  lr = 2e-5, # 학습률\r\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\r\n",
        "                )\r\n",
        "\r\n",
        "# 에폭수\r\n",
        "epochs = 4\r\n",
        "\r\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\r\n",
        "total_steps = len(train_dataloader) * epochs\r\n",
        "\r\n",
        "# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\r\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \r\n",
        "                                            num_warmup_steps = 0,\r\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlryHKWybmv-"
      },
      "source": [
        "# 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9fqecrQbosK"
      },
      "source": [
        "# 정확도 계산 함수\r\n",
        "def flat_accuracy(preds, labels):\r\n",
        "    \r\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "\r\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUnIGcjybqYg"
      },
      "source": [
        "# 시간 표시 함수\r\n",
        "def format_time(elapsed):\r\n",
        "\r\n",
        "    # 반올림\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # hh:mm:ss으로 형태 변경\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzVYJJzsbqb3",
        "outputId": "fc0c9245-7c82-457f-fb9c-58e67efccdfc"
      },
      "source": [
        "# 재현을 위해 랜덤시드 고정\r\n",
        "seed_val = 42\r\n",
        "random.seed(seed_val)\r\n",
        "np.random.seed(seed_val)\r\n",
        "torch.manual_seed(seed_val)\r\n",
        "torch.cuda.manual_seed_all(seed_val)\r\n",
        "\r\n",
        "# 그래디언트 초기화\r\n",
        "model.zero_grad()\r\n",
        "\r\n",
        "# 에폭만큼 반복\r\n",
        "for epoch_i in range(0, epochs):\r\n",
        "    \r\n",
        "    # ========================================\r\n",
        "    #               Training\r\n",
        "    # ========================================\r\n",
        "    \r\n",
        "    print(\"\")\r\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n",
        "    print('Training...')\r\n",
        "\r\n",
        "    # 시작 시간 설정\r\n",
        "    t0 = time.time()\r\n",
        "\r\n",
        "    # 로스 초기화\r\n",
        "    total_loss = 0\r\n",
        "\r\n",
        "    # 훈련모드로 변경\r\n",
        "    model.train()\r\n",
        "        \r\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "    for step, batch in enumerate(train_dataloader):\r\n",
        "        # 경과 정보 표시\r\n",
        "        if step % 500 == 0 and not step == 0:\r\n",
        "            elapsed = format_time(time.time() - t0)\r\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\r\n",
        "\r\n",
        "        # 배치를 GPU에 넣음\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        \r\n",
        "        # 배치에서 데이터 추출\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "\r\n",
        "        # Forward 수행                \r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask, \r\n",
        "                        labels=b_labels)\r\n",
        "        \r\n",
        "        # 로스 구함\r\n",
        "        loss = outputs[0]\r\n",
        "\r\n",
        "        # 총 로스 계산\r\n",
        "        total_loss += loss.item()\r\n",
        "\r\n",
        "        # Backward 수행으로 그래디언트 계산\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # 그래디언트 클리핑\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "\r\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        # 스케줄러로 학습률 감소\r\n",
        "        scheduler.step()\r\n",
        "\r\n",
        "        # 그래디언트 초기화\r\n",
        "        model.zero_grad()\r\n",
        "\r\n",
        "    # 평균 로스 계산\r\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "        \r\n",
        "    # ========================================\r\n",
        "    #               Validation\r\n",
        "    # ========================================\r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"Running Validation...\")\r\n",
        "\r\n",
        "    #시작 시간 설정\r\n",
        "    t0 = time.time()\r\n",
        "\r\n",
        "    # 평가모드로 변경\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # 변수 초기화\r\n",
        "    eval_loss, eval_accuracy = 0, 0\r\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "\r\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "    for batch in validation_dataloader:\r\n",
        "        # 배치를 GPU에 넣음\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        \r\n",
        "        # 배치에서 데이터 추출\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "        \r\n",
        "        # 그래디언트 계산 안함\r\n",
        "        with torch.no_grad():     \r\n",
        "            # Forward 수행\r\n",
        "            outputs = model(b_input_ids, \r\n",
        "                            token_type_ids=None, \r\n",
        "                            attention_mask=b_input_mask)\r\n",
        "        \r\n",
        "        # 로스 구함\r\n",
        "        logits = outputs[0]\r\n",
        "\r\n",
        "        # CPU로 데이터 이동\r\n",
        "        logits = logits.detach().cpu().numpy()\r\n",
        "        label_ids = b_labels.to('cpu').numpy()\r\n",
        "        \r\n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\r\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\r\n",
        "        eval_accuracy += tmp_eval_accuracy\r\n",
        "        nb_eval_steps += 1\r\n",
        "\r\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\r\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of    701.    Elapsed: 0:06:27.\n",
            "\n",
            "  Average training loss: 0.63\n",
            "  Training epcoh took: 0:09:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.68\n",
            "  Validation took: 0:00:20\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of    701.    Elapsed: 0:06:28.\n",
            "\n",
            "  Average training loss: 0.59\n",
            "  Training epcoh took: 0:09:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.67\n",
            "  Validation took: 0:00:20\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of    701.    Elapsed: 0:06:28.\n",
            "\n",
            "  Average training loss: 0.54\n",
            "  Training epcoh took: 0:09:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.67\n",
            "  Validation took: 0:00:20\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of    701.    Elapsed: 0:06:28.\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epcoh took: 0:09:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.67\n",
            "  Validation took: 0:00:20\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrzzoF-sbwNA"
      },
      "source": [
        "# 테스트셋 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fit6V6xtb19m",
        "outputId": "38706384-ead4-439a-8cd1-d736ab574a38"
      },
      "source": [
        "#시작 시간 설정\r\n",
        "t0 = time.time()\r\n",
        "\r\n",
        "# 평가모드로 변경\r\n",
        "model.eval()\r\n",
        "\r\n",
        "# 변수 초기화\r\n",
        "eval_loss, eval_accuracy = 0, 0\r\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "\r\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "for step, batch in enumerate(test_dataloader):\r\n",
        "    # 경과 정보 표시\r\n",
        "    if step % 100 == 0 and not step == 0:\r\n",
        "        elapsed = format_time(time.time() - t0)\r\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\r\n",
        "\r\n",
        "    # 배치를 GPU에 넣음\r\n",
        "    batch = tuple(t.to(device) for t in batch)\r\n",
        "    \r\n",
        "    # 배치에서 데이터 추출\r\n",
        "    b_input_ids, b_input_mask, b_labels = batch\r\n",
        "    \r\n",
        "    # 그래디언트 계산 안함\r\n",
        "    with torch.no_grad():     \r\n",
        "        # Forward 수행\r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask)\r\n",
        "    \r\n",
        "    # 로스 구함\r\n",
        "    logits = outputs[0]\r\n",
        "\r\n",
        "    # CPU로 데이터 이동\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    label_ids = b_labels.to('cpu').numpy()\r\n",
        "    \r\n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\r\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\r\n",
        "    eval_accuracy += tmp_eval_accuracy\r\n",
        "    nb_eval_steps += 1\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\r\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of    195.    Elapsed: 0:00:26.\n",
            "\n",
            "Accuracy: 0.67\n",
            "Test took: 0:00:51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgMrmi3Jn6G7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}